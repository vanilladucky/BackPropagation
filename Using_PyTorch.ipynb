{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: torch.Size([70000, 2]), y_train: torch.Size([70000]), X_test: torch.Size([30000, 2]), y_test = torch.Size([30000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "SimpleModel                              --\n",
       "├─Linear: 1-1                            30\n",
       "├─Linear: 1-2                            11\n",
       "├─Sigmoid: 1-3                           --\n",
       "=================================================================\n",
       "Total params: 41\n",
       "Trainable params: 41\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "import torchinfo \n",
    "from torchinfo import summary \n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def equation(input:torch.Tensor): # z = 5 * a^2 + 3 * b^2\n",
    "    return torch.matmul(torch.mul(input, input), torch.tensor([5, 3], dtype=torch.float32))\n",
    "\n",
    "num_of_data = 100000\n",
    "inputs = torch.randn(num_of_data, 2)\n",
    "outputs = equation(inputs)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "\n",
    "device = torch.device('mps')\n",
    "split = int(inputs.shape[0] * 0.7)\n",
    "X_train, y_train, X_test, y_test = inputs[:split].to(device), outputs[:split].to(device), inputs[split:].to(device), outputs[split:].to(device)\n",
    "print(f\"Shape of X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test = {y_test.shape}\")\n",
    "\n",
    "model = SimpleModel().to(device)\n",
    "summary(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Epoch 0====\n",
      "OrderedDict([('weight', tensor([[-0.4984, -0.5953],\n",
      "        [ 0.3925,  0.0803],\n",
      "        [ 0.5303,  0.6326],\n",
      "        [ 0.3085, -0.0761],\n",
      "        [-0.5978,  0.2972],\n",
      "        [-0.0843, -0.2365],\n",
      "        [ 0.5423, -0.6976],\n",
      "        [-0.1007,  0.5704],\n",
      "        [-0.3974,  0.5895],\n",
      "        [-0.6049, -0.5847]], device='mps:0')), ('bias', tensor([-0.5867, -0.5186, -0.4147,  0.1995, -0.3381, -0.1858, -0.5737, -0.2141,\n",
      "        -0.5028, -0.5999], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[ 0.0915,  0.3023,  0.1852,  0.2384, -0.1829,  0.2571,  0.0949,  0.2068,\n",
      "         -0.0131,  0.2467]], device='mps:0')), ('bias', tensor([0.3007], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:11<00:00, 62.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 45.71417453804071 | Validation Loss: 21.09571307000508\n",
      "====Epoch 1====\n",
      "OrderedDict([('weight', tensor([[-2.4222, -1.7161],\n",
      "        [ 3.0377, -0.1667],\n",
      "        [ 2.9845,  1.0161],\n",
      "        [ 0.0391, -0.0780],\n",
      "        [-2.5859,  0.7425],\n",
      "        [ 0.0514, -0.3375],\n",
      "        [ 2.7544, -1.7347],\n",
      "        [ 0.3097,  2.2876],\n",
      "        [-2.3251,  1.6415],\n",
      "        [-2.9123, -1.0547]], device='mps:0')), ('bias', tensor([-3.4998, -3.7009, -3.7807,  0.1959, -3.3317, -0.2864, -3.7640, -2.3982,\n",
      "        -3.3997, -3.8782], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[5.1687, 5.7475, 5.9135, 0.7232, 4.4631, 0.7141, 6.0694, 3.0183, 4.7189,\n",
      "         5.8861]], device='mps:0')), ('bias', tensor([1.1393], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:10<00:00, 64.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 12.924530703281299 | Validation Loss: 7.860880938262047\n",
      "====Epoch 2====\n",
      "OrderedDict([('weight', tensor([[-1.8588, -2.8719],\n",
      "        [ 3.4279, -0.2854],\n",
      "        [ 3.2102,  1.5446],\n",
      "        [ 0.1000, -0.1051],\n",
      "        [-3.1487,  0.5981],\n",
      "        [ 0.2679, -0.8468],\n",
      "        [ 2.5389, -2.5702],\n",
      "        [ 0.7101,  3.0403],\n",
      "        [-2.4325,  2.3763],\n",
      "        [-3.4160, -0.8406]], device='mps:0')), ('bias', tensor([-4.5872, -4.8932, -5.0073,  0.0766, -4.6298, -0.7480, -4.9375, -3.8897,\n",
      "        -4.6235, -5.0654], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[7.9904, 8.8054, 9.0041, 0.3580, 7.2854, 0.8279, 9.1776, 5.8993, 7.5473,\n",
      "         8.8196]], device='mps:0')), ('bias', tensor([0.4242], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:10<00:00, 65.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.270615682410921 | Validation Loss: 4.93725256198226\n",
      "====Epoch 3====\n",
      "OrderedDict([('weight', tensor([[-1.6381, -2.9611],\n",
      "        [ 3.3938, -0.3154],\n",
      "        [ 3.1823,  1.5183],\n",
      "        [ 0.0860, -0.0981],\n",
      "        [-3.1987,  0.5505],\n",
      "        [ 0.3517, -1.2064],\n",
      "        [ 2.4842, -2.4760],\n",
      "        [ 0.8861,  3.1233],\n",
      "        [-2.4421,  2.4551],\n",
      "        [-3.4107, -0.8552]], device='mps:0')), ('bias', tensor([-5.0412, -5.2982, -5.4171,  0.0705, -5.1005, -1.1679, -5.3325, -4.4940,\n",
      "        -5.0408, -5.4328], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[ 9.4090, 10.3316, 10.5312,  0.3848,  8.8382,  1.3533, 10.6091,  7.3967,\n",
      "          9.0412, 10.3918]], device='mps:0')), ('bias', tensor([0.4820], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:10<00:00, 65.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 4.402378507608678 | Validation Loss: 3.8115064938331527\n",
      "====Epoch 4====\n",
      "OrderedDict([('weight', tensor([[-1.5505, -2.9139],\n",
      "        [ 3.2907, -0.3369],\n",
      "        [ 3.0915,  1.4821],\n",
      "        [ 0.0651, -0.0772],\n",
      "        [-3.1312,  0.5693],\n",
      "        [ 0.3776, -1.4271],\n",
      "        [ 2.4212, -2.3513],\n",
      "        [ 0.9273,  3.1065],\n",
      "        [-2.3950,  2.3821],\n",
      "        [-3.3042, -0.8713]], device='mps:0')), ('bias', tensor([-5.2494, -5.3844, -5.5083,  0.0706, -5.2660, -1.5681, -5.4558, -4.7672,\n",
      "        -5.1562, -5.4862], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[10.3090, 11.2777, 11.4938,  0.4099,  9.8472,  1.8379, 11.4850,  8.3628,\n",
      "          9.9885, 11.3975]], device='mps:0')), ('bias', tensor([0.5450], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:10<00:00, 63.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.5605872514762935 | Validation Loss: 3.2111009803902744\n",
      "====Epoch 5====\n",
      "OrderedDict([('weight', tensor([[-1.4898, -2.8513],\n",
      "        [ 3.1633, -0.3367],\n",
      "        [ 2.9785,  1.4305],\n",
      "        [ 0.0462, -0.0497],\n",
      "        [-3.0259,  0.5626],\n",
      "        [ 0.3756, -1.5757],\n",
      "        [ 2.3583, -2.2288],\n",
      "        [ 0.9150,  3.0491],\n",
      "        [-2.3172,  2.2750],\n",
      "        [-3.1703, -0.8522]], device='mps:0')), ('bias', tensor([-5.3382, -5.3278, -5.4578,  0.0690, -5.2872, -1.9296, -5.4553, -4.8805,\n",
      "        -5.1205, -5.3997], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[10.9655, 11.9600, 12.1980,  0.4096, 10.5864,  2.2617, 12.1127,  9.0684,\n",
      "         10.6732, 12.1294]], device='mps:0')), ('bias', tensor([0.5566], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 699/699 [00:10<00:00, 64.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.0583411743371443 | Validation Loss: 2.8167870870003333\n",
      "====Epoch 6====\n",
      "OrderedDict([('weight', tensor([[-1.4374, -2.7854],\n",
      "        [ 3.0268, -0.3222],\n",
      "        [ 2.8573,  1.3745],\n",
      "        [ 0.0323, -0.0227],\n",
      "        [-2.9077,  0.5413],\n",
      "        [ 0.3486, -1.6997],\n",
      "        [ 2.3018, -2.1087],\n",
      "        [ 0.8737,  2.9778],\n",
      "        [-2.2318,  2.1591],\n",
      "        [-3.0311, -0.8151]], device='mps:0')), ('bias', tensor([-5.3604, -5.2002, -5.3403,  0.0645, -5.2412, -2.2477, -5.3891, -4.9119,\n",
      "        -5.0141, -5.2509], device='mps:0'))])\n",
      "OrderedDict([('weight', tensor([[11.4844, 12.5000, 12.7605,  0.3874, 11.1722,  2.6464, 12.6085,  9.6274,\n",
      "         11.2150, 12.7094]], device='mps:0')), ('bias', tensor([0.5207], device='mps:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 228/699 [00:02<00:04, 97.80it/s] "
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "n_epochs = 10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 100\n",
    "log_interval = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"====Epoch {epoch}====\")\n",
    "\n",
    "    for layer in model.children():\n",
    "        print(layer.state_dict())\n",
    "        \n",
    "    training_loss = 0\n",
    "    training_count = 0\n",
    "    for batch_end_idx in tqdm(range(batch_size, X_train.shape[0], batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X_train[:batch_end_idx])\n",
    "        loss = criterion(out, y_train[:batch_end_idx].view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        training_count += 1\n",
    "\n",
    "    if epoch % log_interval == 0:\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        validation_count = 0\n",
    "        for batch_end_idx in range(batch_size, X_test.shape[0], batch_size):\n",
    "            out = model(X_test[:batch_end_idx])\n",
    "            loss = criterion(out, y_test[:batch_end_idx].view(-1,1))\n",
    "            validation_loss += loss.item()\n",
    "            validation_count += 1\n",
    "        print(f\"Training Loss: {training_loss / training_count} | Validation Loss: {validation_loss / validation_count}\")\n",
    "        model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('machinelearning': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68339890f90b7cc04351217391b998bebccc50e4c246697aa46d0c3bd6df040a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
